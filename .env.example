# ========================================
# CONFLUX Thinking Agents MCP Configuration
# ========================================
# このファイルを .env にコピーして、実際のAPI KEYを設定してください
# cp .env.example .env

# ========================================
# LLM Provider API Keys
# ========================================

# OpenAI GPT models - https://platform.openai.com/api-keys
# 形式: sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# Anthropic Claude models - https://console.anthropic.com/
# 形式: sk-ant-api03-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# ========================================
# Model Configuration
# ========================================

# OpenAI Models
# 利用可能: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-4, gpt-3.5-turbo
# 推奨: gpt-4o (最新・最高性能)
OPENAI_MODEL=gpt-4o

# Anthropic Models  
# 利用可能: claude-3-5-sonnet-20241022, claude-3-haiku-20240307, claude-3-sonnet-20240229
# 推奨: claude-3-5-sonnet-20241022 (最新・最高性能)
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ========================================
# Provider Settings
# ========================================

# デフォルトプロバイダー
# 選択肢: openai, anthropic, mock
# 推奨: anthropic (Claude 3.5 Sonnet)
DEFAULT_LLM_PROVIDER=anthropic

# ========================================
# カスタムプロバイダー（オプション）
# ========================================
# OpenAI互換APIを使用する場合
# CUSTOM_LLM_BASE_URL=https://your-custom-endpoint.com/v1
# CUSTOM_LLM_API_KEY=your-custom-api-key

# ========================================
# 使用方法
# ========================================
# 1. このファイルを .env にコピー:
#    cp .env.example .env
#
# 2. 実際のAPI KEYを設定:
#    - OpenAI: https://platform.openai.com/api-keys
#    - Anthropic: https://console.anthropic.com/
#
# 3. 必要に応じてモデルやプロバイダーを変更
#
# 4. テスト実行:
#    pnpm start single abduction '{"surprisingFact": "APIが遅い"}'
